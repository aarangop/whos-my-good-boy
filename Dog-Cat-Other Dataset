{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":30378,"sourceType":"datasetVersion","datasetId":23777},{"sourceId":4642980,"sourceType":"datasetVersion","datasetId":2699197}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aarangop/dog-cat-other-dataset?scriptVersionId=236427226\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Dog-Cat-Other Dataset\n\nFor my related project, where I try to build a cat, dog, or other classifier, to ultimately be able to recognize my own dog, I need labeled data. In this notebook we create a dataset for this task, based on a subset of the imagenet dataset, and the cat-and-dog dataset.\n\nWe'll build a dataset that contains train, dev, and test sets, according to splits set by the user on this notebook.\n\nThe dataset will consist of images placed inside folders that serve as class names. Since we only have three classes we can just use 'dog', 'cat', and 'other'.","metadata":{}},{"cell_type":"code","source":"import os\nimport shutil\nimport json\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:50:17.111919Z","iopub.execute_input":"2025-04-27T13:50:17.112224Z","iopub.status.idle":"2025-04-27T13:50:17.116949Z","shell.execute_reply.started":"2025-04-27T13:50:17.1122Z","shell.execute_reply":"2025-04-27T13:50:17.115713Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"train_size, dev_size, test_size = 0.8, 0.1, 0.1\n\nassert train_size + dev_size + test_size == 1, \"Train, dev, and test sizes must add up to 1!\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:49:51.635855Z","iopub.execute_input":"2025-04-27T13:49:51.636113Z","iopub.status.idle":"2025-04-27T13:49:51.662294Z","shell.execute_reply.started":"2025-04-27T13:49:51.636091Z","shell.execute_reply":"2025-04-27T13:49:51.661019Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Write required functions","metadata":{}},{"cell_type":"code","source":"def create_dataset_structure(output_path: str, exist_ok=False, reset=False):\n    \"\"\"\n    Creates the folder structure for a new cat/dog/other dataset\n    \"\"\"\n    \n    if reset and os.path.exists(output_path):\n        shutil.rmtree(output_path)\n        \n    for split in ['train', 'dev', 'test']:\n        for category in ['dog', 'cat', 'other']:\n            \n            dirpath = os.path.normpath(f'{output_path}/{split}/{category}')\n            os.makedirs(dirpath, exist_ok=exist_ok)\n\n\ndef get_cat_and_dog_dataset_image_paths():\n    \n    cats = []\n    dogs = []\n    \n    def get_image_paths(dirpath, filenames):\n        # Filter filenames by extension first\n        filenames = filter(lambda f: os.path.splitext(f)[1].lower() == '.jpg', filenames)\n        filenames = [os.path.normpath(f'{dirpath}/{f}') for f in filenames]\n        \n        return filenames\n        \n    for dirpath, dirnames, filenames in os.walk('/kaggle/input/cat-and-dog'):\n        if os.path.basename(dirpath) == 'cats':\n            new_cats = get_image_paths(dirpath, filenames)\n            cats.extend(new_cats)\n        elif os.path.basename(dirpath) == 'dogs':\n            new_dogs = get_image_paths(dirpath, filenames)\n            dogs.extend(new_dogs)\n\n    return cats, dogs\n\ndef shuffle_split(lst, train_size, dev_size, test_size):\n    number_of_samples = len(lst)\n    splits = np.array([train_size, test_size, dev_size])\n    split_sizes = np.floor(number_of_samples * splits).astype(int)\n\n    # Ensure the split sizes sum to the total number of samples\n    if sum(split_sizes) != number_of_samples:\n        # Add the difference to the largest split\n        diff = number_of_samples - sum(split_sizes)\n        split_sizes[np.argmax(splits)] += diff\n    \n    indices = np.arange(number_of_samples)\n\n    # Shuffle indices\n    np.random.shuffle(indices)\n    \n    # Extract train indices\n    train_indices = indices[:split_sizes[0]]\n    \n    # Extract test indices\n    test_indices = indices[split_sizes[0]:split_sizes[0] + split_sizes[1]]\n    \n    # Extract dev indices\n    dev_indices = indices[split_sizes[0] + split_sizes[1]:]\n\n    # Create the actual splits using the indices\n    train_split = [lst[i] for i in train_indices]\n    test_split = [lst[i] for i in test_indices]\n    dev_split = [lst[i] for i in dev_indices]\n    \n    return train_split, test_split, dev_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:49:51.66486Z","iopub.execute_input":"2025-04-27T13:49:51.665204Z","iopub.status.idle":"2025-04-27T13:49:51.683482Z","shell.execute_reply.started":"2025-04-27T13:49:51.665171Z","shell.execute_reply":"2025-04-27T13:49:51.682375Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"cat_dog_other_root = 'cat-dog-other'\nreset_dataset = not os.path.exists(cat_dog_other_root)\ncreate_dataset_structure(cat_dog_other_root, exist_ok=True, reset=reset_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:49:51.684574Z","iopub.execute_input":"2025-04-27T13:49:51.684892Z","iopub.status.idle":"2025-04-27T13:49:51.710805Z","shell.execute_reply.started":"2025-04-27T13:49:51.684868Z","shell.execute_reply":"2025-04-27T13:49:51.70988Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Moving cat-dog-dataset to cat-dog-other","metadata":{}},{"cell_type":"code","source":"# Get a list of all the filepaths for dogs, and cats from the cat-and-dog dataset.\ncats, dogs = get_cat_and_dog_dataset_image_paths()\nprint(f'Collected {len(cats)} cat images, and {len(dogs)} dog images')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:49:51.711811Z","iopub.execute_input":"2025-04-27T13:49:51.712065Z","iopub.status.idle":"2025-04-27T13:50:04.502378Z","shell.execute_reply.started":"2025-04-27T13:49:51.712042Z","shell.execute_reply":"2025-04-27T13:50:04.501488Z"}},"outputs":[{"name":"stdout","text":"Collected 5011 cat images, and 5017 dog images\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Shuffle the cat and dog images into train, test, and dev\ntrain_size, test_size, dev_size = 0.8, 0.1, 0.1\ncat_images = shuffle_split(cats, train_size, dev_size, test_size)\ndog_images = shuffle_split(dogs, train_size, dev_size, test_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:50:04.503346Z","iopub.execute_input":"2025-04-27T13:50:04.503688Z","iopub.status.idle":"2025-04-27T13:50:04.588121Z","shell.execute_reply.started":"2025-04-27T13:50:04.503651Z","shell.execute_reply":"2025-04-27T13:50:04.585913Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2154246481.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Shuffle the cat and dog images into train, test, and dev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcat_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdog_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2387474350.py\u001b[0m in \u001b[0;36mshuffle_split\u001b[0;34m(lst, train_size, dev_size, test_size)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mshuffle_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mnumber_of_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0msplits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0msplit_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_samples\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"],"ename":"NameError","evalue":"name 'np' is not defined","output_type":"error"}],"execution_count":6},{"cell_type":"markdown","source":"## Add cats and dogs images to dataset","metadata":{}},{"cell_type":"code","source":"skipped = 0\nfor (class_name, splits) in zip(('cat', 'dog'), (cat_images, dog_images)):\n    for (split, source) in zip(('train', 'test', 'dev'), splits):\n        dest_dir = os.path.normpath(f'{cat_dog_other_root}/{split}/{class_name}')\n        for image in source:\n            file_name = os.path.basename(image)\n            dest_file = os.path.normpath(f'{dest_dir}/{file_name}')\n            if not os.path.exists(dest_file):\n                shutil.copy(image, dest_file)\n\nprint(f'{skipped} files were skipped because they were already copied')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:50:04.589386Z","iopub.status.idle":"2025-04-27T13:50:04.589779Z","shell.execute_reply.started":"2025-04-27T13:50:04.589587Z","shell.execute_reply":"2025-04-27T13:50:04.589611Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Get Imagenet cats, dogs, and other","metadata":{}},{"cell_type":"code","source":"# We first need the class names and the labels used by the imagenet dataset\n# Load miniimagenet object classes\nwith open('/kaggle/input/miniimagenet/ImageNet-Mini/imagenet_class_index.json') as f:\n    obj_classes = json.load(f)\n    obj_classes = [(i, *obj_classes[str(i)]) for i, obj_class in enumerate(obj_classes)]\n    class_names = {class_key: class_name for idx, class_key, class_name in obj_classes}\n    \nprint(f'There are {len(class_names)} in the dataset.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:50:04.590793Z","iopub.status.idle":"2025-04-27T13:50:04.59108Z","shell.execute_reply.started":"2025-04-27T13:50:04.590954Z","shell.execute_reply":"2025-04-27T13:50:04.590968Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find dog and cat classes\ndog_indices = []\ncat_indices = []\nother_indices = []\n\nfor idx, key, name in obj_classes:\n    # For dogs, we look for common dog breeds and the word 'dog'\n    if (('dog' in name.lower() or \n        'hound' in name.lower() or \n        'terrier' in name.lower() or \n        'shepherd' in name.lower() or\n        'retriever' in name.lower() or\n        'spaniel' in name.lower() or\n        'poodle' in name.lower() or\n        'collie' in name.lower()) and not (\n        'hotdog' in name.lower() or\n        'dogsled' in name.lower()\n        )):\n        dog_indices.append(idx)\n    elif ('cat' in name.lower() or \n        'tabby' in name.lower() or \n        'siamese' in name.lower() or\n        'persian' in name.lower()):\n        cat_indices.append(idx)\n    else:\n        other_indices.append(idx)\n\ndog_classes = [obj_classes[idx][1] for idx in dog_indices]\ncat_classes = [obj_classes[idx][1] for idx in cat_indices]\nother_classes = [obj_classes[idx][1] for idx in other_indices]\n\nprint(\"Found\")\nprint(f\"\\t{len(dog_indices)} dog classes,\")\nprint(f\"\\t{len(cat_indices)} cat classes,and\")\nprint(f\"\\t{len(other_indices)} other classes\")\n\n# Save text files for documentation containing the new class taxonomy\nfor indices, cls in zip((dog_indices, cat_indices, other_indices), ('dog', 'cat', 'other')):\n    with open(os.path.join(cat_dog_other_root, f'{cls}_classes.txt'), 'w') as f:\n        classes = [obj_classes[idx] for idx in indices]\n        classes = [f\"{i}. {key}: {class_name}\" for i, key, class_name in classes]\n        f.write(\"\\n\".join(classes))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:50:04.592408Z","iopub.status.idle":"2025-04-27T13:50:04.592767Z","shell.execute_reply.started":"2025-04-27T13:50:04.592574Z","shell.execute_reply":"2025-04-27T13:50:04.592591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"imagenet_images_dir = '/kaggle/input/miniimagenet/ImageNet-Mini/images'\n\nimagenet_dogs = []\nimagenet_cats = []\nimagenet_other = []\n\n# Walk through imagenet dataset and sort the dog, cat, and other classes\nfor dirname, dirnames, filenames in os.walk(imagenet_images_dir):\n    # Get class key\n    class_key = os.path.basename(dirname)\n    # See if it matches cat, dog, or other\n    if class_key in dog_classes:\n        imagenet_dogs.append(dirname)\n    if class_key in cat_classes:\n        imagenet_cats.append(dirname)\n    if class_key in other_classes:\n        imagenet_other.append(dirname)\n\nprint(f'Found {len(imagenet_dogs)} dog classes, {len(imagenet_cats)} cat classes, and {len(imagenet_other)} other classes.')\nprint(f'Total number of classes: {len(imagenet_dogs) + len(imagenet_cats) + len(imagenet_other)} (should add up to 1000)')\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:50:04.593668Z","iopub.status.idle":"2025-04-27T13:50:04.593973Z","shell.execute_reply.started":"2025-04-27T13:50:04.593852Z","shell.execute_reply":"2025-04-27T13:50:04.593865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Now that we've got the directories for cats, dogs and other,\n# we collect a list with the actual images\nimagenet_dog_images = []\nimagenet_cat_images = []\nimagenet_other_images = []\n\nfor superclass, dirs, images in zip(\n    ('dog', 'cat', 'other'), \n    (imagenet_dogs, imagenet_cats, imagenet_other),\n    (imagenet_dog_images, imagenet_cat_images, imagenet_other_images)\n    ):\n    # Get list of files\n    for dirname in dirs:\n        filenames = os.listdir(dirname)\n        filenames = [os.path.normpath(f'{dirname}/{f}') for f in filenames if os.path.splitext(f)[1].lower() == '.jpeg']\n        images.extend(filenames)\n\nprint('Collected')\nprint(f' {len(imagenet_dog_images)} dog images')\nprint(f' {len(imagenet_cat_images)} cat images')\nprint(f' {len(imagenet_other_images)} other images')\nprint('from miniimagenet dataset')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:50:04.59561Z","iopub.status.idle":"2025-04-27T13:50:04.595991Z","shell.execute_reply.started":"2025-04-27T13:50:04.595803Z","shell.execute_reply":"2025-04-27T13:50:04.595821Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Now shuffle split the imagenet images\ncat_images = shuffle_split(imagenet_cat_images, train_size, test_size, dev_size)\ndog_images = shuffle_split(imagenet_dog_images, train_size, test_size, dev_size)\nother_images = shuffle_split(imagenet_other_images, train_size, test_size, dev_size)\n\n# Add the images to the new dataset\nskipped = 0\nfor (class_name, splits) in zip(('cat', 'dog', 'other'), (cat_images, dog_images, other_images)):\n    for (split, source) in zip(('train', 'test', 'dev'), splits):\n        dest_dir = os.path.normpath(f'{cat_dog_other_root}/{split}/{class_name}')\n        for img in source:\n            file_name = os.path.basename(img)\n            dest_file = os.path.normpath(f'{dest_dir}/{file_name}')\n            if not os.path.exists(dest_file):\n                shutil.copy(img, dest_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:50:04.597555Z","iopub.status.idle":"2025-04-27T13:50:04.597899Z","shell.execute_reply.started":"2025-04-27T13:50:04.597751Z","shell.execute_reply":"2025-04-27T13:50:04.597771Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install kaggle package if not already installed\n!pip install -q kaggle\n\n# Set up credentials (if needed)\n# You'll need your Kaggle API credentials from your account settings\n# You can upload kaggle.json to your notebook or set env variables\n\n# Create metadata for your dataset\n!mkdir -p /kaggle/working/dataset-metadata\n%%writefile /kaggle/working/dataset-metadata/dataset-metadata.json\n{\n  \"title\": \"Cat-Dog-Other Classification Dataset\",\n  \"id\": \"yourusername/cat-dog-other\",\n  \"licenses\": [\n    {\n      \"name\": \"ODbL-1.0\"\n    }\n  ]\n}\n\n# Create the dataset directly from your notebook\n!kaggle datasets create -p /kaggle/working/cat-dog-other -r zip","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T13:50:04.599849Z","iopub.status.idle":"2025-04-27T13:50:04.600249Z","shell.execute_reply.started":"2025-04-27T13:50:04.600058Z","shell.execute_reply":"2025-04-27T13:50:04.600072Z"}},"outputs":[],"execution_count":null}]}