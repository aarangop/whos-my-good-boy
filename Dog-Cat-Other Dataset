{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aarangop/dog-cat-other-dataset?scriptVersionId=236444216\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"e1e1f74e","metadata":{"papermill":{"duration":0.005203,"end_time":"2025-04-27T15:29:43.312429","exception":false,"start_time":"2025-04-27T15:29:43.307226","status":"completed"},"tags":[]},"source":["# Dog-Cat-Other Dataset\n","\n","For my related project, where I try to build a cat, dog, or other classifier, to ultimately be able to recognize my own dog, I need labeled data. In this notebook we create a dataset for this task, based on a subset of the imagenet dataset, and the cat-and-dog dataset.\n","\n","We'll build a dataset that contains train, dev, and test sets, according to splits set by the user on this notebook.\n","\n","The dataset will consist of images placed inside folders that serve as class names. Since we only have three classes we can just use 'dog', 'cat', and 'other'."]},{"cell_type":"code","execution_count":1,"id":"41b28440","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:29:43.323115Z","iopub.status.busy":"2025-04-27T15:29:43.322737Z","iopub.status.idle":"2025-04-27T15:29:43.332258Z","shell.execute_reply":"2025-04-27T15:29:43.331046Z"},"papermill":{"duration":0.017155,"end_time":"2025-04-27T15:29:43.334193","exception":false,"start_time":"2025-04-27T15:29:43.317038","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","import shutil\n","import json\n","import numpy as np\n","from typing import List, Tuple\n","import glob"]},{"cell_type":"markdown","id":"7eb56df3","metadata":{"papermill":{"duration":0.004044,"end_time":"2025-04-27T15:29:43.342848","exception":false,"start_time":"2025-04-27T15:29:43.338804","status":"completed"},"tags":[]},"source":["## Configuration"]},{"cell_type":"code","execution_count":2,"id":"574871ae","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:29:43.352576Z","iopub.status.busy":"2025-04-27T15:29:43.352282Z","iopub.status.idle":"2025-04-27T15:29:43.357207Z","shell.execute_reply":"2025-04-27T15:29:43.356183Z"},"papermill":{"duration":0.011911,"end_time":"2025-04-27T15:29:43.358979","exception":false,"start_time":"2025-04-27T15:29:43.347068","status":"completed"},"tags":[]},"outputs":[],"source":["train_size, dev_size, test_size = 0.8, 0.1, 0.1\n","\n","assert train_size + dev_size + test_size == 1, \"Train, dev, and test sizes must add up to 1!\""]},{"cell_type":"markdown","id":"608c09fa","metadata":{"papermill":{"duration":0.003297,"end_time":"2025-04-27T15:29:43.366321","exception":false,"start_time":"2025-04-27T15:29:43.363024","status":"completed"},"tags":[]},"source":["## Write required functions"]},{"cell_type":"code","execution_count":3,"id":"9b8f0c2d","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:29:43.37634Z","iopub.status.busy":"2025-04-27T15:29:43.375955Z","iopub.status.idle":"2025-04-27T15:29:43.390174Z","shell.execute_reply":"2025-04-27T15:29:43.389212Z"},"papermill":{"duration":0.02207,"end_time":"2025-04-27T15:29:43.392093","exception":false,"start_time":"2025-04-27T15:29:43.370023","status":"completed"},"tags":[]},"outputs":[],"source":["def create_dataset_structure(output_path: str, exist_ok=False, reset=False):\n","    \"\"\"\n","    Creates the folder structure for a new cat/dog/other dataset\n","    \"\"\"\n","    \n","    if reset and os.path.exists(output_path):\n","        shutil.rmtree(output_path)\n","        \n","    for split in ['train', 'dev', 'test']:\n","        for category in ['dog', 'cat', 'other']:\n","            \n","            dirpath = os.path.normpath(f'{output_path}/{split}/{category}')\n","            os.makedirs(dirpath, exist_ok=exist_ok)\n","\n","\n","def get_cat_and_dog_dataset_image_paths():\n","    \n","    cats = []\n","    dogs = []\n","    \n","    def get_image_paths(dirpath, filenames):\n","        # Filter filenames by extension first\n","        filenames = filter(lambda f: os.path.splitext(f)[1].lower() == '.jpg', filenames)\n","        filenames = [os.path.normpath(f'{dirpath}/{f}') for f in filenames]\n","        \n","        return filenames\n","        \n","    for dirpath, dirnames, filenames in os.walk('/kaggle/input/cat-and-dog'):\n","        if os.path.basename(dirpath) == 'cats':\n","            new_cats = get_image_paths(dirpath, filenames)\n","            cats.extend(new_cats)\n","        elif os.path.basename(dirpath) == 'dogs':\n","            new_dogs = get_image_paths(dirpath, filenames)\n","            dogs.extend(new_dogs)\n","\n","    return cats, dogs\n","\n","def shuffle_split(lst, train_size, dev_size, test_size):\n","    number_of_samples = len(lst)\n","    splits = np.array([train_size, test_size, dev_size])\n","    split_sizes = np.floor(number_of_samples * splits).astype(int)\n","\n","    # Ensure the split sizes sum to the total number of samples\n","    if sum(split_sizes) != number_of_samples:\n","        # Add the difference to the largest split\n","        diff = number_of_samples - sum(split_sizes)\n","        split_sizes[np.argmax(splits)] += diff\n","    \n","    indices = np.arange(number_of_samples)\n","\n","    # Shuffle indices\n","    np.random.shuffle(indices)\n","    \n","    # Extract train indices\n","    train_indices = indices[:split_sizes[0]]\n","    \n","    # Extract test indices\n","    test_indices = indices[split_sizes[0]:split_sizes[0] + split_sizes[1]]\n","    \n","    # Extract dev indices\n","    dev_indices = indices[split_sizes[0] + split_sizes[1]:]\n","\n","    # Create the actual splits using the indices\n","    train_split = [lst[i] for i in train_indices]\n","    test_split = [lst[i] for i in test_indices]\n","    dev_split = [lst[i] for i in dev_indices]\n","    \n","    return train_split, test_split, dev_split\n","\n","def copy_class_split_files(\n","    paths: List[str],\n","    class_name: str,\n","    split: str,\n","    dest_root: str,\n","    start_i: int = 10_000\n","    ):\n","    \"\"\"\n","    Copies files from image_paths into the dest_dir, following the pattern:\n","\n","    dest_dir/split/class_name/<class_name>_<split>_<i>.*\n","\n","    # Arguments\n","    - class_names: a tuple of strings with the class names\n","    - image_paths: a tuple of lists, containing the paths to the files for each class.\n","    - \n","    \"\"\"\n","    dest_dir = os.path.join(dest_root, split, class_name)\n","    i = max(len(os.listdir(dest_dir)), start_i)\n","    copied_files = []\n","    for source in paths:\n","        file_name = os.path.basename(source)\n","        file_ext = os.path.splitext(file_name)[1].lower()\n","        dest_name = f'{class_name}_{split}_{i}{file_ext}'\n","        dest_file = os.path.join(dest_dir, dest_name)\n","        if not os.path.exists(dest_file):\n","            shutil.copy(source, dest_file)\n","            i += 1\n","            copied_files.append(dest_file)\n","\n","    return copied_files"]},{"cell_type":"code","execution_count":4,"id":"c91f2633","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:29:43.401347Z","iopub.status.busy":"2025-04-27T15:29:43.401023Z","iopub.status.idle":"2025-04-27T15:29:43.407202Z","shell.execute_reply":"2025-04-27T15:29:43.406107Z"},"papermill":{"duration":0.013005,"end_time":"2025-04-27T15:29:43.409138","exception":false,"start_time":"2025-04-27T15:29:43.396133","status":"completed"},"tags":[]},"outputs":[],"source":["cat_dog_other_root = 'cat-dog-other'\n","create_dataset_structure(cat_dog_other_root, exist_ok=True, reset=True)"]},{"cell_type":"markdown","id":"0366dc71","metadata":{"papermill":{"duration":0.003469,"end_time":"2025-04-27T15:29:43.417002","exception":false,"start_time":"2025-04-27T15:29:43.413533","status":"completed"},"tags":[]},"source":["## Moving cat-dog-dataset to cat-dog-other"]},{"cell_type":"code","execution_count":5,"id":"ae5fd332","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:29:43.425859Z","iopub.status.busy":"2025-04-27T15:29:43.425459Z","iopub.status.idle":"2025-04-27T15:29:57.749977Z","shell.execute_reply":"2025-04-27T15:29:57.748801Z"},"papermill":{"duration":14.33118,"end_time":"2025-04-27T15:29:57.751905","exception":false,"start_time":"2025-04-27T15:29:43.420725","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collected 5011 cat images, and 5017 dog images\n"]}],"source":["# Get a list of all the filepaths for dogs, and cats from the cat-and-dog dataset.\n","cats, dogs = get_cat_and_dog_dataset_image_paths()\n","print(f'Collected {len(cats)} cat images, and {len(dogs)} dog images')"]},{"cell_type":"code","execution_count":6,"id":"48a79e6b","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:29:57.761312Z","iopub.status.busy":"2025-04-27T15:29:57.761017Z","iopub.status.idle":"2025-04-27T15:29:57.772536Z","shell.execute_reply":"2025-04-27T15:29:57.771559Z"},"papermill":{"duration":0.018454,"end_time":"2025-04-27T15:29:57.774383","exception":false,"start_time":"2025-04-27T15:29:57.755929","status":"completed"},"tags":[]},"outputs":[],"source":["# Shuffle the cat and dog images into train, test, and dev\n","train_size, test_size, dev_size = 0.8, 0.1, 0.1\n","cat_images = shuffle_split(cats, train_size, dev_size, test_size)\n","dog_images = shuffle_split(dogs, train_size, dev_size, test_size)"]},{"cell_type":"markdown","id":"67fc03c6","metadata":{"papermill":{"duration":0.003689,"end_time":"2025-04-27T15:29:57.782133","exception":false,"start_time":"2025-04-27T15:29:57.778444","status":"completed"},"tags":[]},"source":["## Add cats and dogs images to dataset"]},{"cell_type":"code","execution_count":7,"id":"09fa4945","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:29:57.792172Z","iopub.status.busy":"2025-04-27T15:29:57.791865Z","iopub.status.idle":"2025-04-27T15:30:55.129861Z","shell.execute_reply":"2025-04-27T15:30:55.128904Z"},"papermill":{"duration":57.348781,"end_time":"2025-04-27T15:30:55.135167","exception":false,"start_time":"2025-04-27T15:29:57.786386","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["10028 files copied to cat-dog-other\n"]}],"source":["copied_files = []\n","for (class_name, splits) in zip(('cat', 'dog'), (cat_images, dog_images)):\n","    for (split_name, paths) in zip(('train', 'test', 'dev'), splits):\n","        copied_files.extend(\n","            copy_class_split_files(paths, class_name, split_name, cat_dog_other_root)\n","        )\n","        \n","print(f'{len(copied_files)} files copied to {cat_dog_other_root}')"]},{"cell_type":"markdown","id":"cb1d2898","metadata":{"papermill":{"duration":0.003836,"end_time":"2025-04-27T15:30:55.143205","exception":false,"start_time":"2025-04-27T15:30:55.139369","status":"completed"},"tags":[]},"source":["## Get Imagenet cats, dogs, and other from imagenet"]},{"cell_type":"code","execution_count":8,"id":"8e8bb493","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:30:55.154125Z","iopub.status.busy":"2025-04-27T15:30:55.153306Z","iopub.status.idle":"2025-04-27T15:30:55.178212Z","shell.execute_reply":"2025-04-27T15:30:55.176841Z"},"papermill":{"duration":0.033167,"end_time":"2025-04-27T15:30:55.180403","exception":false,"start_time":"2025-04-27T15:30:55.147236","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 1000 in the dataset.\n"]}],"source":["# We first need the class names and the labels used by the imagenet dataset\n","# Load miniimagenet object classes\n","with open('/kaggle/input/miniimagenet/ImageNet-Mini/imagenet_class_index.json') as f:\n","    obj_classes = json.load(f)\n","    obj_classes = [(i, *obj_classes[str(i)]) for i, obj_class in enumerate(obj_classes)]\n","    class_names = {class_key: class_name for idx, class_key, class_name in obj_classes}\n","    \n","print(f'There are {len(class_names)} in the dataset.')"]},{"cell_type":"code","execution_count":9,"id":"ee56831a","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:30:55.190691Z","iopub.status.busy":"2025-04-27T15:30:55.190395Z","iopub.status.idle":"2025-04-27T15:30:55.204139Z","shell.execute_reply":"2025-04-27T15:30:55.202858Z"},"papermill":{"duration":0.021185,"end_time":"2025-04-27T15:30:55.206199","exception":false,"start_time":"2025-04-27T15:30:55.185014","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Found\n","\t56 dog classes,\n","\t9 cat classes,and\n","\t935 other classes\n"]}],"source":["# Find dog and cat classes\n","dog_indices = []\n","cat_indices = []\n","other_indices = []\n","\n","for idx, key, name in obj_classes:\n","    # For dogs, we look for common dog breeds and the word 'dog'\n","    if (('dog' in name.lower() or \n","        'hound' in name.lower() or \n","        'terrier' in name.lower() or \n","        'shepherd' in name.lower() or\n","        'retriever' in name.lower() or\n","        'spaniel' in name.lower() or\n","        'poodle' in name.lower() or\n","        'collie' in name.lower()) and not (\n","        'hotdog' in name.lower() or\n","        'dogsled' in name.lower()\n","        )):\n","        dog_indices.append(idx)\n","    elif ('cat' in name.lower() or \n","        'tabby' in name.lower() or \n","        'siamese' in name.lower() or\n","        'persian' in name.lower()):\n","        cat_indices.append(idx)\n","    else:\n","        other_indices.append(idx)\n","\n","dog_classes = [obj_classes[idx][1] for idx in dog_indices]\n","cat_classes = [obj_classes[idx][1] for idx in cat_indices]\n","other_classes = [obj_classes[idx][1] for idx in other_indices]\n","\n","print(\"Found\")\n","print(f\"\\t{len(dog_indices)} dog classes,\")\n","print(f\"\\t{len(cat_indices)} cat classes,and\")\n","print(f\"\\t{len(other_indices)} other classes\")\n","\n","# Save text files for documentation containing the new class taxonomy\n","for indices, cls in zip((dog_indices, cat_indices, other_indices), ('dog', 'cat', 'other')):\n","    with open(os.path.join(cat_dog_other_root, f'{cls}_classes.txt'), 'w') as f:\n","        classes = [obj_classes[idx] for idx in indices]\n","        classes = [f\"{i}. {key}: {class_name}\" for i, key, class_name in classes]\n","        f.write(\"\\n\".join(classes))"]},{"cell_type":"code","execution_count":10,"id":"3f1bffa4","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:30:55.217684Z","iopub.status.busy":"2025-04-27T15:30:55.216608Z","iopub.status.idle":"2025-04-27T15:31:03.813637Z","shell.execute_reply":"2025-04-27T15:31:03.812524Z"},"papermill":{"duration":8.604494,"end_time":"2025-04-27T15:31:03.815552","exception":false,"start_time":"2025-04-27T15:30:55.211058","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 56 dog classes, 9 cat classes, and 935 other classes.\n","Total number of classes: 1000 (should add up to 1000)\n"]}],"source":["imagenet_images_dir = '/kaggle/input/miniimagenet/ImageNet-Mini/images'\n","\n","imagenet_dogs = []\n","imagenet_cats = []\n","imagenet_other = []\n","\n","# Walk through imagenet dataset and sort the dog, cat, and other classes\n","for dirname, dirnames, filenames in os.walk(imagenet_images_dir):\n","    # Get class key\n","    class_key = os.path.basename(dirname)\n","    # See if it matches cat, dog, or other\n","    if class_key in dog_classes:\n","        imagenet_dogs.append(dirname)\n","    if class_key in cat_classes:\n","        imagenet_cats.append(dirname)\n","    if class_key in other_classes:\n","        imagenet_other.append(dirname)\n","\n","print(f'Found {len(imagenet_dogs)} dog classes, {len(imagenet_cats)} cat classes, and {len(imagenet_other)} other classes.')\n","print(f'Total number of classes: {len(imagenet_dogs) + len(imagenet_cats) + len(imagenet_other)} (should add up to 1000)')\n","    "]},{"cell_type":"code","execution_count":11,"id":"13d75874","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:31:03.825628Z","iopub.status.busy":"2025-04-27T15:31:03.825342Z","iopub.status.idle":"2025-04-27T15:31:04.414299Z","shell.execute_reply":"2025-04-27T15:31:04.413025Z"},"papermill":{"duration":0.595966,"end_time":"2025-04-27T15:31:04.416031","exception":false,"start_time":"2025-04-27T15:31:03.820065","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collected\n"," 202 dog images\n"," 44 cat images\n"," 3677 other images\n","from miniimagenet dataset\n"]}],"source":["# Now that we've got the directories for cats, dogs and other,\n","# we collect a list with the actual image file paths\n","imagenet_dog_images = []\n","imagenet_cat_images = []\n","imagenet_other_images = []\n","\n","for superclass, dirs, images in zip(\n","    ('dog', 'cat', 'other'), \n","    (imagenet_dogs, imagenet_cats, imagenet_other),\n","    (imagenet_dog_images, imagenet_cat_images, imagenet_other_images)\n","    ):\n","    # Get list of files\n","    for dirname in dirs:\n","        filenames = os.listdir(dirname)\n","        filenames = [os.path.normpath(f'{dirname}/{f}') for f in filenames if os.path.splitext(f)[1].lower() == '.jpeg']\n","        images.extend(filenames)\n","\n","print('Collected')\n","print(f' {len(imagenet_dog_images)} dog images')\n","print(f' {len(imagenet_cat_images)} cat images')\n","print(f' {len(imagenet_other_images)} other images')\n","print('from miniimagenet dataset')"]},{"cell_type":"code","execution_count":12,"id":"7ce7af15","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:31:04.42682Z","iopub.status.busy":"2025-04-27T15:31:04.42624Z","iopub.status.idle":"2025-04-27T15:31:44.14006Z","shell.execute_reply":"2025-04-27T15:31:44.138938Z"},"papermill":{"duration":39.725024,"end_time":"2025-04-27T15:31:44.145412","exception":false,"start_time":"2025-04-27T15:31:04.420388","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Copied 3923 imagenet files to cat-dog-other\n"]}],"source":["# Now shuffle split the imagenet images\n","cat_images = shuffle_split(imagenet_cat_images, train_size, test_size, dev_size)\n","dog_images = shuffle_split(imagenet_dog_images, train_size, test_size, dev_size)\n","other_images = shuffle_split(imagenet_other_images, train_size, test_size, dev_size)\n","\n","# Add the images to the new dataset\n","copied_imagenet_files = []\n","for (class_name, splits) in zip(('cat', 'dog', 'other'), (cat_images, dog_images, other_images)):\n","    for (split, paths) in zip(('train', 'test', 'dev'), splits):\n","        copied_imagenet_files.extend(\n","            copy_class_split_files(paths, class_name, split, cat_dog_other_root)\n","        )\n","\n","print(f'Copied {len(copied_imagenet_files)} imagenet files to {cat_dog_other_root}')"]},{"cell_type":"code","execution_count":13,"id":"42b61ed8","metadata":{"execution":{"iopub.execute_input":"2025-04-27T15:31:44.15509Z","iopub.status.busy":"2025-04-27T15:31:44.154655Z","iopub.status.idle":"2025-04-27T15:31:44.286799Z","shell.execute_reply":"2025-04-27T15:31:44.28567Z"},"papermill":{"duration":0.138969,"end_time":"2025-04-27T15:31:44.288458","exception":false,"start_time":"2025-04-27T15:31:44.149489","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Summary:\n","Images per class:\n"," - 5055 cat images\n"," - 5219 dog images\n"," - 3677 other images\n","Total for all classes: 13951\n","\n","Images per split:\n"," - 11165 images in train set\n"," - 1393 images in dev set\n"," - 1393 images in test set\n","Total for all sets: 13951\n"]}],"source":["# Make a summary of what's happened\n","all_images = []\n","\n","images_per_split = {\n","    'train': [],\n","    'dev': [],\n","    'test': []\n","}\n","images_per_class = {\n","    'cat': [],\n","    'dog': [],\n","    'other': []\n","}\n","\n","\n","print(\"Summary:\")\n","\n","print(\"Images per class:\")\n","img_types = ('jpg', 'jpeg', 'png')\n","\n","for class_name in images_per_class.keys():\n","    pattern = f'{cat_dog_other_root}/**/{class_name}/*'\n","    images = []\n","    for img_ext in img_types:\n","        images.extend(glob.iglob(f'{pattern}.{img_ext}'))\n","    images_per_class[class_name].extend(images)\n","    print(f' - {len(images_per_class[class_name])} {class_name} images')\n","\n","total_per_class = sum([len(images) for _, images in images_per_class.items()])\n","print(f\"Total for all classes: {total_per_class}\")\n","\n","print(\"\\nImages per split:\")\n","for split in images_per_split.keys():\n","    pattern = f'{cat_dog_other_root}/{split}/**/*'\n","    images = []\n","    for img_ext in img_types:\n","        images.extend(glob.iglob(f'{pattern}.{img_ext}'))\n","    images_per_split[split].extend(images)\n","    print(f' - {len(images_per_split[split])} images in {split} set')\n","total_per_split = sum([len(images) for _, images in images_per_split.items()])\n","print(f\"Total for all sets: {total_per_split}\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":23777,"sourceId":30378,"sourceType":"datasetVersion"},{"datasetId":2699197,"sourceId":4642980,"sourceType":"datasetVersion"}],"dockerImageVersionId":31012,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":126.897139,"end_time":"2025-04-27T15:31:44.713966","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-27T15:29:37.816827","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}