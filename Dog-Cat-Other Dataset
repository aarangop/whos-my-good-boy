{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aarangop/dog-cat-other-dataset-creation?scriptVersionId=236488185\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","id":"a684da0f","metadata":{"papermill":{"duration":0.005212,"end_time":"2025-04-27T20:59:40.841447","exception":false,"start_time":"2025-04-27T20:59:40.836235","status":"completed"},"tags":[]},"source":["# Dog-Cat-Other Dataset\n","\n","For my related project, where I try to build a cat, dog, or other classifier, to ultimately be able to recognize my own dog, I need labeled data. In this notebook we create a dataset for this task, based on a subset of the imagenet dataset, and the cat-and-dog dataset.\n","\n","We'll build a dataset that contains train, dev, and test sets, according to splits set by the user on this notebook.\n","\n","The dataset will consist of images placed inside folders that serve as class names. Since we only have three classes we can just use 'dog', 'cat', and 'other'."]},{"cell_type":"code","execution_count":1,"id":"9b1972a2","metadata":{"execution":{"iopub.execute_input":"2025-04-27T20:59:40.850615Z","iopub.status.busy":"2025-04-27T20:59:40.850185Z","iopub.status.idle":"2025-04-27T20:59:40.858052Z","shell.execute_reply":"2025-04-27T20:59:40.857318Z"},"papermill":{"duration":0.014244,"end_time":"2025-04-27T20:59:40.859682","exception":false,"start_time":"2025-04-27T20:59:40.845438","status":"completed"},"tags":[]},"outputs":[],"source":["import os\n","import shutil\n","import json\n","import numpy as np\n","from typing import List, Tuple\n","import glob"]},{"cell_type":"markdown","id":"9bb84f3f","metadata":{"papermill":{"duration":0.003403,"end_time":"2025-04-27T20:59:40.867057","exception":false,"start_time":"2025-04-27T20:59:40.863654","status":"completed"},"tags":[]},"source":["## Configuration"]},{"cell_type":"code","execution_count":2,"id":"e67045f9","metadata":{"execution":{"iopub.execute_input":"2025-04-27T20:59:40.875715Z","iopub.status.busy":"2025-04-27T20:59:40.875412Z","iopub.status.idle":"2025-04-27T20:59:40.880059Z","shell.execute_reply":"2025-04-27T20:59:40.87921Z"},"papermill":{"duration":0.010791,"end_time":"2025-04-27T20:59:40.881542","exception":false,"start_time":"2025-04-27T20:59:40.870751","status":"completed"},"tags":[]},"outputs":[],"source":["train_size, dev_size, test_size = 0.8, 0.1, 0.1\n","\n","assert train_size + dev_size + test_size == 1, \"Train, dev, and test sizes must add up to 1!\""]},{"cell_type":"markdown","id":"6a8fd811","metadata":{"papermill":{"duration":0.003457,"end_time":"2025-04-27T20:59:40.88893","exception":false,"start_time":"2025-04-27T20:59:40.885473","status":"completed"},"tags":[]},"source":["## Required functions"]},{"cell_type":"code","execution_count":3,"id":"e39fcb62","metadata":{"execution":{"iopub.execute_input":"2025-04-27T20:59:40.897689Z","iopub.status.busy":"2025-04-27T20:59:40.897335Z","iopub.status.idle":"2025-04-27T20:59:40.912889Z","shell.execute_reply":"2025-04-27T20:59:40.911938Z"},"papermill":{"duration":0.02189,"end_time":"2025-04-27T20:59:40.914426","exception":false,"start_time":"2025-04-27T20:59:40.892536","status":"completed"},"tags":[]},"outputs":[],"source":["def create_dataset_structure(output_path: str, exist_ok=False, reset=False):\n","    \"\"\"\n","    Creates the folder structure for a new cat/dog/other dataset.\n","    \n","    Parameters\n","    ----------\n","    output_path : str\n","        Path where the dataset folder structure will be created\n","    exist_ok : bool, optional\n","        If True, doesn't raise an error if directories already exist (default is False)\n","    reset : bool, optional\n","        If True, deletes the output_path directory if it exists before creating new structure (default is False)\n","    \n","    Returns\n","    -------\n","    None\n","    \"\"\"\n","    \n","    if reset and os.path.exists(output_path):\n","        shutil.rmtree(output_path)\n","        \n","    for split in ['train', 'dev', 'test']:\n","        for category in ['dog', 'cat', 'other']:\n","            \n","            dirpath = os.path.normpath(f'{output_path}/{split}/{category}')\n","            os.makedirs(dirpath, exist_ok=exist_ok)\n","\n","\n","def get_cat_and_dog_dataset_image_paths():\n","    \"\"\"\n","    Retrieves paths to cat and dog images from the Kaggle cat and dog dataset.\n","    \n","    Walks through the '/kaggle/input/cat-and-dog' directory and collects paths\n","    to all JPG files in 'cats' and 'dogs' subdirectories.\n","    \n","    Returns\n","    -------\n","    tuple\n","        A tuple containing two lists:\n","        - List of paths to cat images\n","        - List of paths to dog images\n","    \"\"\"\n","    \n","    cats = []\n","    dogs = []\n","    \n","    def get_image_paths(dirpath, filenames):\n","        # Filter filenames by extension first\n","        filenames = filter(lambda f: os.path.splitext(f)[1].lower() == '.jpg', filenames)\n","        filenames = [os.path.normpath(f'{dirpath}/{f}') for f in filenames]\n","        \n","        return filenames\n","        \n","    for dirpath, dirnames, filenames in os.walk('/kaggle/input/cat-and-dog'):\n","        if os.path.basename(dirpath) == 'cats':\n","            new_cats = get_image_paths(dirpath, filenames)\n","            cats.extend(new_cats)\n","        elif os.path.basename(dirpath) == 'dogs':\n","            new_dogs = get_image_paths(dirpath, filenames)\n","            dogs.extend(new_dogs)\n","    return cats, dogs\n","\n","\n","def shuffle_split(lst, train_size, dev_size, test_size):\n","    \"\"\"\n","    Randomly splits a list into training, testing, and development sets.\n","    \n","    Parameters\n","    ----------\n","    lst : list\n","        The list of items to split\n","    train_size : float\n","        Proportion of items to include in the training set (0.0 to 1.0)\n","    dev_size : float\n","        Proportion of items to include in the development set (0.0 to 1.0)\n","    test_size : float\n","        Proportion of items to include in the testing set (0.0 to 1.0)\n","    \n","    Returns\n","    -------\n","    tuple\n","        A tuple containing three lists:\n","        - Training set\n","        - Testing set\n","        - Development set\n","    \n","    Notes\n","    -----\n","    The sum of train_size, dev_size, and test_size should equal 1.0.\n","    If there's a rounding difference, extra items are added to the largest split.\n","    \"\"\"\n","    number_of_samples = len(lst)\n","    splits = np.array([train_size, test_size, dev_size])\n","    split_sizes = np.floor(number_of_samples * splits).astype(int)\n","    # Ensure the split sizes sum to the total number of samples\n","    if sum(split_sizes) != number_of_samples:\n","        # Add the difference to the largest split\n","        diff = number_of_samples - sum(split_sizes)\n","        split_sizes[np.argmax(splits)] += diff\n","    \n","    indices = np.arange(number_of_samples)\n","    # Shuffle indices\n","    np.random.shuffle(indices)\n","    \n","    # Extract train indices\n","    train_indices = indices[:split_sizes[0]]\n","    \n","    # Extract test indices\n","    test_indices = indices[split_sizes[0]:split_sizes[0] + split_sizes[1]]\n","    \n","    # Extract dev indices\n","    dev_indices = indices[split_sizes[0] + split_sizes[1]:]\n","    # Create the actual splits using the indices\n","    train_split = [lst[i] for i in train_indices]\n","    test_split = [lst[i] for i in test_indices]\n","    dev_split = [lst[i] for i in dev_indices]\n","    \n","    return train_split, test_split, dev_split\n","\n","\n","def copy_class_split_files(\n","    paths: List[str],\n","    class_name: str,\n","    split: str,\n","    dest_root: str,\n","    start_i: int = 10_000\n","    ):\n","    \"\"\"\n","    Copies image files to a destination directory following a specific naming pattern.\n","    \n","    Copies files from source paths to a destination directory following the pattern:\n","    dest_root/split/class_name/class_name_split_i.ext\n","    \n","    Parameters\n","    ----------\n","    paths : List[str]\n","        List of source file paths to copy\n","    class_name : str\n","        Name of the class (e.g., 'cat', 'dog')\n","    split : str\n","        Dataset split name (e.g., 'train', 'test', 'dev')\n","    dest_root : str\n","        Root directory for the destination dataset\n","    start_i : int, optional\n","        Starting index for file numbering (default is 10,000)\n","    \n","    Returns\n","    -------\n","    list\n","        List of paths to the newly copied files\n","    \n","    Notes\n","    -----\n","    File numbering starts from the maximum of start_i or the current number of files \n","    in the destination directory.\n","    \"\"\"\n","    dest_dir = os.path.join(dest_root, split, class_name)\n","    n_files_in_dir = len(os.listdir(dest_dir))\n","    i = start_i + n_files_in_dir + 1\n","    print(f\"There are {n_files_in_dir} files in '{dest_dir}', starting with index: {i}\")\n","    copied_files = []\n","    for source in paths:\n","        file_name = os.path.basename(source)\n","        file_ext = os.path.splitext(file_name)[1].lower()\n","        dest_name = f'{class_name}_{split}_{i}{file_ext}'\n","        dest_file = os.path.join(dest_dir, dest_name)\n","        if not os.path.exists(dest_file):\n","            shutil.copy(source, dest_file)\n","            i += 1\n","            copied_files.append(dest_file)\n","    print(f\"Copied {len(copied_files)} files to '{dest_dir}'\")\n","    return copied_files"]},{"cell_type":"code","execution_count":4,"id":"afb12131","metadata":{"execution":{"iopub.execute_input":"2025-04-27T20:59:40.92322Z","iopub.status.busy":"2025-04-27T20:59:40.922914Z","iopub.status.idle":"2025-04-27T20:59:40.928136Z","shell.execute_reply":"2025-04-27T20:59:40.927135Z"},"papermill":{"duration":0.011427,"end_time":"2025-04-27T20:59:40.929708","exception":false,"start_time":"2025-04-27T20:59:40.918281","status":"completed"},"tags":[]},"outputs":[],"source":["cat_dog_other_root = 'cat-dog-other'\n","create_dataset_structure(cat_dog_other_root, exist_ok=True, reset=True)"]},{"cell_type":"markdown","id":"e864d948","metadata":{"papermill":{"duration":0.003357,"end_time":"2025-04-27T20:59:40.936905","exception":false,"start_time":"2025-04-27T20:59:40.933548","status":"completed"},"tags":[]},"source":["## Moving cat-dog-dataset to cat-dog-other"]},{"cell_type":"code","execution_count":5,"id":"e126774b","metadata":{"execution":{"iopub.execute_input":"2025-04-27T20:59:40.945566Z","iopub.status.busy":"2025-04-27T20:59:40.944973Z","iopub.status.idle":"2025-04-27T20:59:48.30759Z","shell.execute_reply":"2025-04-27T20:59:48.306586Z"},"papermill":{"duration":7.368592,"end_time":"2025-04-27T20:59:48.30916","exception":false,"start_time":"2025-04-27T20:59:40.940568","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collected 5011 cat images, and 5017 dog images from cat-and-dog dataset\n"]}],"source":["# Get a list of all the filepaths for dogs, and cats from the cat-and-dog dataset.\n","cats, dogs = get_cat_and_dog_dataset_image_paths()\n","print(f'Collected {len(cats)} cat images, and {len(dogs)} dog images from cat-and-dog dataset')"]},{"cell_type":"code","execution_count":6,"id":"f98aa286","metadata":{"execution":{"iopub.execute_input":"2025-04-27T20:59:48.318185Z","iopub.status.busy":"2025-04-27T20:59:48.317897Z","iopub.status.idle":"2025-04-27T20:59:48.327243Z","shell.execute_reply":"2025-04-27T20:59:48.326393Z"},"papermill":{"duration":0.015742,"end_time":"2025-04-27T20:59:48.329007","exception":false,"start_time":"2025-04-27T20:59:48.313265","status":"completed"},"tags":[]},"outputs":[],"source":["# Shuffle the cat and dog images into train, test, and dev\n","train_size, test_size, dev_size = 0.8, 0.1, 0.1\n","cat_images = shuffle_split(cats, train_size, dev_size, test_size)\n","dog_images = shuffle_split(dogs, train_size, dev_size, test_size)"]},{"cell_type":"markdown","id":"77de8463","metadata":{"papermill":{"duration":0.00355,"end_time":"2025-04-27T20:59:48.336383","exception":false,"start_time":"2025-04-27T20:59:48.332833","status":"completed"},"tags":[]},"source":["## Add cats and dogs images to dataset"]},{"cell_type":"code","execution_count":7,"id":"e241a473","metadata":{"execution":{"iopub.execute_input":"2025-04-27T20:59:48.345153Z","iopub.status.busy":"2025-04-27T20:59:48.344861Z","iopub.status.idle":"2025-04-27T21:00:24.672404Z","shell.execute_reply":"2025-04-27T21:00:24.671297Z"},"papermill":{"duration":36.33365,"end_time":"2025-04-27T21:00:24.673857","exception":false,"start_time":"2025-04-27T20:59:48.340207","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Copying files from cat-and-dog dataset\n","There are 0 files in 'cat-dog-other/train/cat', starting with index: 10001\n","Copied 4009 files to 'cat-dog-other/train/cat'\n","There are 0 files in 'cat-dog-other/test/cat', starting with index: 10001\n","Copied 501 files to 'cat-dog-other/test/cat'\n","There are 0 files in 'cat-dog-other/dev/cat', starting with index: 10001\n","Copied 501 files to 'cat-dog-other/dev/cat'\n","There are 0 files in 'cat-dog-other/train/dog', starting with index: 10001\n","Copied 4015 files to 'cat-dog-other/train/dog'\n","There are 0 files in 'cat-dog-other/test/dog', starting with index: 10001\n","Copied 501 files to 'cat-dog-other/test/dog'\n","There are 0 files in 'cat-dog-other/dev/dog', starting with index: 10001\n","Copied 501 files to 'cat-dog-other/dev/dog'\n","\n","10028 files copied to cat-dog-other\n"]}],"source":["print('Copying files from cat-and-dog dataset')\n","copied_files = []\n","for (class_name, splits) in zip(('cat', 'dog'), (cat_images, dog_images)):\n","    for (split_name, paths) in zip(('train', 'test', 'dev'), splits):\n","        copied_files.extend(\n","            copy_class_split_files(paths, class_name, split_name, cat_dog_other_root)\n","        )\n","        \n","print(f'\\n{len(copied_files)} files copied to {cat_dog_other_root}')"]},{"cell_type":"markdown","id":"0522578e","metadata":{"papermill":{"duration":0.003945,"end_time":"2025-04-27T21:00:24.682026","exception":false,"start_time":"2025-04-27T21:00:24.678081","status":"completed"},"tags":[]},"source":["## Get Imagenet cats, dogs, and other from imagenet"]},{"cell_type":"code","execution_count":8,"id":"a1e98654","metadata":{"execution":{"iopub.execute_input":"2025-04-27T21:00:24.691011Z","iopub.status.busy":"2025-04-27T21:00:24.690752Z","iopub.status.idle":"2025-04-27T21:00:24.704739Z","shell.execute_reply":"2025-04-27T21:00:24.703802Z"},"papermill":{"duration":0.020148,"end_time":"2025-04-27T21:00:24.706106","exception":false,"start_time":"2025-04-27T21:00:24.685958","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 1000 labels in the MiniImagenet dataset.\n"]}],"source":["# We first need the class names and the labels used by the imagenet dataset\n","# Load miniimagenet object classes\n","with open('/kaggle/input/miniimagenet/ImageNet-Mini/imagenet_class_index.json') as f:\n","    obj_classes = json.load(f)\n","    obj_classes = [(i, *obj_classes[str(i)]) for i, obj_class in enumerate(obj_classes)]\n","    class_names = {class_key: class_name for idx, class_key, class_name in obj_classes}\n","\n","# Copy the json file too for documentation purposes\n","shutil.copy('/kaggle/input/miniimagenet/ImageNet-Mini/imagenet_class_index.json', \n","            os.path.join(cat_dog_other_root, 'imagenet_class_index.json'))\n","print(f'There are {len(class_names)} labels in the MiniImagenet dataset.')"]},{"cell_type":"code","execution_count":9,"id":"53ff1aed","metadata":{"execution":{"iopub.execute_input":"2025-04-27T21:00:24.715608Z","iopub.status.busy":"2025-04-27T21:00:24.71529Z","iopub.status.idle":"2025-04-27T21:00:24.731439Z","shell.execute_reply":"2025-04-27T21:00:24.730438Z"},"papermill":{"duration":0.022658,"end_time":"2025-04-27T21:00:24.732952","exception":false,"start_time":"2025-04-27T21:00:24.710294","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Found\n","\t56 dog classes,\n","\t9 cat classes,and\n","\t935 other classes\n"]}],"source":["# Find dog and cat classes\n","dog_indices = []\n","cat_indices = []\n","other_indices = []\n","\n","for idx, key, name in obj_classes:\n","    # For dogs, we look for common dog breeds and the word 'dog'\n","    if (('dog' in name.lower() or \n","        'hound' in name.lower() or \n","        'terrier' in name.lower() or \n","        'shepherd' in name.lower() or\n","        'retriever' in name.lower() or\n","        'spaniel' in name.lower() or\n","        'poodle' in name.lower() or\n","        'collie' in name.lower()) and not (\n","        'hotdog' in name.lower() or\n","        'dogsled' in name.lower()\n","        )):\n","        dog_indices.append(idx)\n","    elif ('cat' in name.lower() or \n","        'tabby' in name.lower() or \n","        'siamese' in name.lower() or\n","        'persian' in name.lower()):\n","        cat_indices.append(idx)\n","    else:\n","        other_indices.append(idx)\n","\n","dog_classes = [obj_classes[idx][1] for idx in dog_indices]\n","cat_classes = [obj_classes[idx][1] for idx in cat_indices]\n","other_classes = [obj_classes[idx][1] for idx in other_indices]\n","\n","print(\"Found\")\n","print(f\"\\t{len(dog_indices)} dog classes,\")\n","print(f\"\\t{len(cat_indices)} cat classes,and\")\n","print(f\"\\t{len(other_indices)} other classes\")\n","\n","# Save text files for documentation containing the new class taxonomy\n","for indices, cls in zip((dog_indices, cat_indices, other_indices), ('dog', 'cat', 'other')):\n","    with open(os.path.join(cat_dog_other_root, f'{cls}_classes.txt'), 'w') as f:\n","        classes = [obj_classes[idx] for idx in indices]\n","        classes = [f\"{i}. {key}: {class_name}\" for i, key, class_name in classes]\n","        f.write(\"\\n\".join(classes))\n","    with open(os.path.join(cat_dog_other_root, f'{cls}_classes.json'), 'w') as f:\n","        classes = {idx: obj_classes[idx] for idx in indices}\n","        json.dump(classes, f)\n"]},{"cell_type":"code","execution_count":10,"id":"91a81367","metadata":{"execution":{"iopub.execute_input":"2025-04-27T21:00:24.742972Z","iopub.status.busy":"2025-04-27T21:00:24.742677Z","iopub.status.idle":"2025-04-27T21:00:28.755288Z","shell.execute_reply":"2025-04-27T21:00:28.754344Z"},"papermill":{"duration":4.019387,"end_time":"2025-04-27T21:00:28.756788","exception":false,"start_time":"2025-04-27T21:00:24.737401","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 56 dog classes, 9 cat classes, and 935 other classes.\n","Total number of classes: 1000 (should add up to 1000)\n"]}],"source":["imagenet_images_dir = '/kaggle/input/miniimagenet/ImageNet-Mini/images'\n","\n","imagenet_dogs = []\n","imagenet_cats = []\n","imagenet_other = []\n","\n","# Walk through imagenet dataset and sort the dog, cat, and other classes\n","for dirname, dirnames, filenames in os.walk(imagenet_images_dir):\n","    # Get class key\n","    class_key = os.path.basename(dirname)\n","    # See if it matches cat, dog, or other\n","    if class_key in dog_classes:\n","        imagenet_dogs.append(dirname)\n","    if class_key in cat_classes:\n","        imagenet_cats.append(dirname)\n","    if class_key in other_classes:\n","        imagenet_other.append(dirname)\n","\n","print(f'Found {len(imagenet_dogs)} dog classes, {len(imagenet_cats)} cat classes, and {len(imagenet_other)} other classes.')\n","print(f'Total number of classes: {len(imagenet_dogs) + len(imagenet_cats) + len(imagenet_other)} (should add up to 1000)')\n","    "]},{"cell_type":"code","execution_count":11,"id":"b29f69ed","metadata":{"execution":{"iopub.execute_input":"2025-04-27T21:00:28.766844Z","iopub.status.busy":"2025-04-27T21:00:28.766567Z","iopub.status.idle":"2025-04-27T21:00:29.284021Z","shell.execute_reply":"2025-04-27T21:00:29.282905Z"},"papermill":{"duration":0.524797,"end_time":"2025-04-27T21:00:29.285937","exception":false,"start_time":"2025-04-27T21:00:28.76114","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Collected\n"," 202 dog image paths\n"," 44 cat image paths\n"," 3677 other image paths\n","from MiniImagenet dataset\n"]}],"source":["# Now that we've got the directories for cats, dogs and other,\n","# we collect a list with the actual image file paths\n","imagenet_dog_images = []\n","imagenet_cat_images = []\n","imagenet_other_images = []\n","\n","for superclass, dirs, images in zip(\n","    ('dog', 'cat', 'other'), \n","    (imagenet_dogs, imagenet_cats, imagenet_other),\n","    (imagenet_dog_images, imagenet_cat_images, imagenet_other_images)\n","    ):\n","    # Get list of files\n","    for dirname in dirs:\n","        filenames = os.listdir(dirname)\n","        filenames = [os.path.normpath(f'{dirname}/{f}') for f in filenames if os.path.splitext(f)[1].lower() == '.jpeg']\n","        images.extend(filenames)\n","\n","print('Collected')\n","print(f' {len(imagenet_dog_images)} dog image paths')\n","print(f' {len(imagenet_cat_images)} cat image paths')\n","print(f' {len(imagenet_other_images)} other image paths')\n","print('from MiniImagenet dataset')"]},{"cell_type":"code","execution_count":12,"id":"df47ae46","metadata":{"execution":{"iopub.execute_input":"2025-04-27T21:00:29.296062Z","iopub.status.busy":"2025-04-27T21:00:29.295275Z","iopub.status.idle":"2025-04-27T21:00:49.559006Z","shell.execute_reply":"2025-04-27T21:00:49.557967Z"},"papermill":{"duration":20.270622,"end_time":"2025-04-27T21:00:49.560917","exception":false,"start_time":"2025-04-27T21:00:29.290295","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Copying files from MiniImagenet dataset\n","There are 4009 files in 'cat-dog-other/train/cat', starting with index: 14010\n","Copied 36 files to 'cat-dog-other/train/cat'\n","There are 501 files in 'cat-dog-other/test/cat', starting with index: 10502\n","Copied 4 files to 'cat-dog-other/test/cat'\n","There are 501 files in 'cat-dog-other/dev/cat', starting with index: 10502\n","Copied 4 files to 'cat-dog-other/dev/cat'\n","There are 4015 files in 'cat-dog-other/train/dog', starting with index: 14016\n","Copied 162 files to 'cat-dog-other/train/dog'\n","There are 501 files in 'cat-dog-other/test/dog', starting with index: 10502\n","Copied 20 files to 'cat-dog-other/test/dog'\n","There are 501 files in 'cat-dog-other/dev/dog', starting with index: 10502\n","Copied 20 files to 'cat-dog-other/dev/dog'\n","There are 0 files in 'cat-dog-other/train/other', starting with index: 10001\n","Copied 2943 files to 'cat-dog-other/train/other'\n","There are 0 files in 'cat-dog-other/test/other', starting with index: 10001\n","Copied 367 files to 'cat-dog-other/test/other'\n","There are 0 files in 'cat-dog-other/dev/other', starting with index: 10001\n","Copied 367 files to 'cat-dog-other/dev/other'\n","\n","Copied 3923 imagenet files to cat-dog-other\n"]}],"source":["# Now shuffle split the imagenet images\n","cat_images = shuffle_split(imagenet_cat_images, train_size, test_size, dev_size)\n","dog_images = shuffle_split(imagenet_dog_images, train_size, test_size, dev_size)\n","other_images = shuffle_split(imagenet_other_images, train_size, test_size, dev_size)\n","\n","print('Copying files from MiniImagenet dataset')\n","# Add the images to the new dataset\n","copied_imagenet_files = []\n","for (class_name, splits) in zip(('cat', 'dog', 'other'), (cat_images, dog_images, other_images)):\n","    for (split, paths) in zip(('train', 'test', 'dev'), splits):\n","        copied_imagenet_files.extend(\n","            copy_class_split_files(paths, class_name, split, cat_dog_other_root)\n","        )\n","\n","print(f'\\nCopied {len(copied_imagenet_files)} imagenet files to {cat_dog_other_root}')"]},{"cell_type":"code","execution_count":13,"id":"f7af4902","metadata":{"execution":{"iopub.execute_input":"2025-04-27T21:00:49.572463Z","iopub.status.busy":"2025-04-27T21:00:49.572131Z","iopub.status.idle":"2025-04-27T21:00:49.706417Z","shell.execute_reply":"2025-04-27T21:00:49.705312Z"},"papermill":{"duration":0.141532,"end_time":"2025-04-27T21:00:49.708148","exception":false,"start_time":"2025-04-27T21:00:49.566616","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Summary:\n","Images per class:\n"," - 5055 cat images\n"," - 5219 dog images\n"," - 3677 other images\n","Total for all classes: 13951\n","\n","Images per split:\n"," - 11165 images in train set ~ 80.03%\n"," - 1393 images in dev set ~ 9.98%\n"," - 1393 images in test set ~ 9.98%\n","Total for all sets: 13951\n"]}],"source":["# Make a summary of what's happened\n","all_images = []\n","\n","images_per_split = {\n","    'train': [],\n","    'dev': [],\n","    'test': []\n","}\n","images_per_class = {\n","    'cat': [],\n","    'dog': [],\n","    'other': []\n","}\n","\n","\n","print(\"Summary:\")\n","\n","print(\"Images per class:\")\n","img_types = ('jpg', 'jpeg', 'png')\n","\n","for class_name in images_per_class.keys():\n","    pattern = f'{cat_dog_other_root}/**/{class_name}/*'\n","    images = []\n","    for img_ext in img_types:\n","        images.extend(glob.iglob(f'{pattern}.{img_ext}'))\n","    images_per_class[class_name].extend(images)\n","    print(f' - {len(images_per_class[class_name])} {class_name} images')\n","\n","total_per_class = sum([len(images) for _, images in images_per_class.items()])\n","print(f\"Total for all classes: {total_per_class}\")\n","\n","print(\"\\nImages per split:\")\n","for split in images_per_split.keys():\n","    pattern = f'{cat_dog_other_root}/{split}/**/*'\n","    images = []\n","    for img_ext in img_types:\n","        images.extend(glob.iglob(f'{pattern}.{img_ext}'))\n","    images_per_split[split].extend(images)\n","    n_images = len(images_per_split[split])\n","    print(f' - {n_images} images in {split} set ~ {100 * n_images/total_per_class:.2f}%')\n","    \n","total_per_split = sum([len(images) for _, images in images_per_split.items()])\n","print(f\"Total for all sets: {total_per_split}\")\n","\n","assert total_per_class == total_per_split, \"The totals per class and totals per split must add up to the same value!\""]},{"cell_type":"code","execution_count":null,"id":"2af729fd","metadata":{"papermill":{"duration":0.00451,"end_time":"2025-04-27T21:00:49.717629","exception":false,"start_time":"2025-04-27T21:00:49.713119","status":"completed"},"tags":[]},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":23777,"sourceId":30378,"sourceType":"datasetVersion"},{"datasetId":2699197,"sourceId":4642980,"sourceType":"datasetVersion"}],"dockerImageVersionId":31012,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"papermill":{"default_parameters":{},"duration":74.036163,"end_time":"2025-04-27T21:00:50.141483","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-27T20:59:36.10532","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}